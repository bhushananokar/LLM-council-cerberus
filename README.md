# LLM Council - AI-Powered Security

An intelligent multi-agent system for analyzing software packages and detecting Open Source code security threats using Large Language Models.

**Frontend Repo**: https://github.com/bhushananokar/cerberus-frontend

## ðŸŽ¯ Project Context

**LLM Council is part of a comprehensive Open Source code security platform.** This component focuses on the AI-powered decision-making layer that receives pre-processed package intelligence from upstream static analysis tools.

### Complete Pipeline Architecture

```
Package Analysis â†’ Static Checks â†’ JSON Input â†’ LLM Council â†’ Risk Assessment
     â†“               â†“                â†“            â†“              â†“
  Registry        Code Scanner    Structured    Multi-Agent   Final Decision
  Download        Behavioral       Package         AI         + MongoDB
                  Analysis          Data         Analysis      Storage
                                                    â†“
                                               Overseer
                                             Validation
```

**Input Source**: The JSON data containing package metadata, code segments, static analysis results, behavioral patterns, and dependency information is generated by separate static analysis tools that perform:
- Code scanning and pattern detection
- Behavioral analysis and syscall monitoring
- Dependency tree analysis and typosquatting detection
- Entropy analysis and obfuscation scoring

**This system processes that pre-analyzed data through multiple AI agents to make final security decisions.**

> **âš¡ Future Enhancement**: The LLMs will be fine-tuned on security-specific datasets including known malicious packages, vulnerability patterns, and Open Source code attack signatures. This fine-tuning will significantly improve detection accuracy, reduce false positives, and enable the system to recognize novel attack patterns.

## Overview

LLM Council employs a collaborative AI approach where multiple specialized agents analyze packages from different security perspectives:
- **Code Intelligence Agent**: Analyzes source code patterns, suspicious APIs, and obfuscation
- **Threat Intelligence Agent**: Evaluates threat indicators and malicious patterns
- **Behavioral Intelligence Agent**: Assesses runtime behavior and system interactions
- **Overseer Agent**: Validates agent outputs, detects hallucinations, ensures response quality, and flags inconsistencies

When agents disagree, an automated debate system conducts multi-round discussions to reach consensus, with the Overseer monitoring debate quality and ensuring logical consistency. All results are stored in MongoDB for analysis and auditing.

---

## Architecture

### Multi-Agent System with Overseer
```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Package Input â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      â”‚                      â”‚
                â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Code Intelligence â”‚  â”‚Threat Intelligenceâ”‚  â”‚Behavioral Intel   â”‚
    â”‚      Agent        â”‚  â”‚      Agent        â”‚  â”‚     Agent         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                       â”‚                       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  Overseer Agent â”‚
                            â”‚   Validation    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Consensus Builderâ”‚
                          â”‚  & Debate System â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Final Decision  â”‚
                          â”‚  + MongoDB      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Overseer Agent Role

The **Overseer Agent** is a critical quality control component that:

1. **Validates Agent Responses**: 
   - Checks if responses are well-structured and complete
   - Verifies risk scores are within valid ranges (0-100)
   - Ensures confidence scores are reasonable
   - Validates verdict consistency with risk scores

2. **Detects Hallucinations**:
   - Identifies fabricated code patterns not in input
   - Flags made-up package metadata or statistics
   - Detects contradictory statements within responses
   - Ensures evidence cited actually exists in input data

3. **Quality Assurance**:
   - Verifies explanations match the assigned risk score
   - Ensures technical accuracy of security assessments
   - Checks for logical consistency across agent responses
   - Flags vague or generic responses lacking specificity

4. **Debate Monitoring**:
   - Supervises debate rounds for logical consistency
   - Identifies circular arguments or repeated points
   - Ensures agents address each other's evidence
   - Validates position changes are evidence-based

5. **Output Enhancement**:
   - Flags low-quality responses for re-analysis
   - Adds confidence adjustments based on validation
   - Provides meta-commentary on analysis quality
   - Triggers human review when inconsistencies detected

### Debate System
When agents disagree (variance > threshold):
1. Automated multi-round debate initiated (max 10 rounds)
2. Agents present evidence and counter-arguments
3. **Overseer monitors debate quality and logical consistency**
4. Positions tracked and analyzed for convergence
5. Consensus reached through structured discussion
6. Results stored in MongoDB for audit trail

### Data Persistence
- **MongoDB**: Stores all analysis results, debate transcripts, and overseer validations
- **Caching**: Redis-style in-memory cache for repeated queries
- **Logging**: Comprehensive logging to file and console

---

## Key Features

### 1. Multi-Agent Collaboration
- Three specialized security analysis agents
- Independent risk assessments from different perspectives
- Weighted consensus building based on confidence scores

### 2. Overseer Validation
- **Hallucination Detection**: Prevents fabricated security findings
- **Quality Control**: Ensures responses meet minimum quality standards
- **Consistency Checking**: Validates risk scores match explanations
- **Evidence Verification**: Confirms cited evidence exists in input data
- **Debate Quality Monitoring**: Ensures logical and productive discussions

### 3. Automated Debate Resolution
- Multi-round structured debates (up to 10 rounds)
- Evidence-based argumentation with overseer supervision
- Position tracking and convergence detection
- Complete debate transcripts for transparency

### 4. Comprehensive Threat Detection
- Base64 encoded malicious payloads
- Environment variable exfiltration
- Remote code execution patterns
- Credential harvesting indicators
- Backdoor installation detection
- Obfuscated code analysis
- Typosquatting and package name similarity checks
- Supply chain attack pattern recognition

### 5. Production-Ready API
- FastAPI with automatic documentation
- MongoDB integration for persistence
- Health checks and system statistics
- Flexible LLM provider support
- Token usage and cost tracking

---

## Setup Instructions

### Prerequisites

- Python 3.10+
- MongoDB (local or Atlas)
- API keys for LLM providers (Groq, OpenAI, Anthropic, etc.)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd llm-council
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   
   Create a `.env` file in the project root:
   ```env
   # LLM Provider Configuration
   GROQ_API_KEY=your_groq_api_key
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   GOOGLE_AI_API_KEY=your_google_ai_api_key
   
   # LLM Settings
   LLM_PROVIDER=groq
   MODEL_NAME=llama-3.3-70b-versatile
   MAX_TOKENS=2000
   TEMPERATURE=0.1
   
   # MongoDB Configuration
   MONGODB_URI=mongodb://localhost:27017
   DATABASE_NAME=llm_council
   
   # Agent Configuration
   AGENT1_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
   AGENT1_WEIGHT=0.30
   AGENT2_MODEL=openai/gpt-oss-120b
   AGENT2_WEIGHT=0.35
   AGENT3_MODEL=gemini-2.0-flash
   AGENT3_WEIGHT=0.35
   
   # Application Settings
   LOG_LEVEL=INFO
   ENABLE_CACHING=true
   CACHE_TTL_SECONDS=3600
   ```

5. **Start MongoDB**
   ```bash
   # Local MongoDB
   mongod
   
   # Or use MongoDB Atlas connection string in .env
   ```

6. **Run the API server**
   ```bash
   python -m uvicorn api.main:app --reload --host 0.0.0.0 --port 8080
   ```

   Server will be available at `http://localhost:8080`

---

## API Structure

### Base URL
```
http://localhost:8080
```

### Endpoints

#### 1. Analyze Package
**POST** `/analyze`

Analyzes a software package for security threats using the multi-agent council with overseer validation.

**Request Body:**
```json
{
  "package_data": {
    "package_name": "suspicious-crypto-lib",
    "version": "1.0.0",
    "registry": "npm",
    "description": "Cryptocurrency utilities",
    "author": "unknown-author",
    "downloads_last_month": 150,
    "package_age_days": 5,
    "code_segments": [
      {
        "code": "eval(Buffer.from('base64string', 'base64').toString())",
        "location": "index.js:45",
        "reason": "eval_with_base64"
      }
    ],
    "static_analysis": {
      "high_entropy_count": 3,
      "dangerous_apis": ["eval", "exec", "child_process"],
      "obfuscation_score": 85,
      "suspicious_patterns": ["base64_decode", "environment_access"]
    },
    "behavioral_analysis": {
      "network_connections": [
        {"host": "malicious-domain.com", "port": 443, "protocol": "https"}
      ],
      "file_operations": [
        {"operation": "read", "path": "/etc/passwd"}
      ],
      "environment_accessed": true,
      "process_spawned": true
    },
    "dependency_analysis": {
      "total_dependencies": 25,
      "suspicious_dependencies": ["crypto-stealer"],
      "typosquatting_similarity": 0.95,
      "similar_to": "crypto-js"
    }
  }
}
```

**Response:**
```json
{
  "decision_id": "decision_abc123",
  "package_name": "suspicious-crypto-lib",
  "package_version": "1.0.0",
  "verdict": "malicious",
  "final_risk_score": 96.0,
  "final_confidence": 92.0,
  "threat_level": "critical",
  "requires_human_review": false,
  "consensus_result": {
    "final_risk_score": 96.0,
    "final_confidence": 92.0,
    "final_verdict": "malicious",
    "threat_level": "critical",
    "agreement_level": "strong",
    "variance": 4.0,
    "agent_scores": {
      "code_intelligence": 96,
      "threat_intelligence": 98,
      "behavioral_intelligence": 94
    },
    "agent_verdicts": {
      "code_intelligence": "malicious",
      "threat_intelligence": "malicious",
      "behavioral_intelligence": "malicious"
    },
    "debate_conducted": false,
    "debate_result": null,
    "flag_for_review": false,
    "explanation": "Strong consensus detected. Code contains credential theft with network exfiltration.",
    "total_tokens_used": 2200
  },
  "agent_responses": [
    {
      "agent_name": "code_intelligence",
      "model_name": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "risk_score": 96,
      "confidence": 92,
      "verdict": "malicious",
      "explanation": "Code uses eval() with base64 decoding to execute hidden payload...",
      "tokens_used": 750
    }
  ],
  "overseer_validation": {
    "validation_passed": true,
    "quality_score": 95,
    "hallucination_detected": false,
    "consistency_issues": [],
    "recommendations": []
  },
  "total_tokens_used": 2200,
  "estimated_cost_usd": 0.0101,
  "analysis_duration_seconds": 4.2
}
```

**Status Codes:**
- `200` - Analysis completed successfully
- `400` - Invalid request body
- `422` - Validation error
- `500` - Internal server error

---

#### 2. Health Check
**GET** `/health`

Check system health and agent availability.

**Response:**
```json
{
  "status": "healthy",
  "service": "llm-council",
  "version": "1.0.0",
  "timestamp": "2026-02-01T20:30:00Z",
  "mongodb": "connected",
  "agents": {
    "code_intelligence": "meta-llama/llama-4-maverick-17b-128e-instruct",
    "threat_intelligence": "openai/gpt-oss-120b",
    "behavioral_intelligence": "gemini-2.0-flash"
  },
  "environment": "production"
}
```

---

### MongoDB Query Endpoints

#### 3. Get All Analyses
**GET** `/api/v1/council/analyses`

Query stored analysis results.

**Query Parameters:**
- `skip` (int): Number of records to skip (pagination, default: 0)
- `limit` (int): Maximum records to return (default: 100)

**Response:**
```json
{
  "success": true,
  "analyses": [
    {
      "decision_id": "decision_abc123",
      "package_name": "suspicious-crypto-lib",
      "package_version": "1.0.0",
      "verdict": "malicious",
      "final_risk_score": 96.0,
      "threat_level": "critical",
      "created_at": "2026-02-01T20:30:00Z"
    }
  ],
  "count": 1,
  "total": 1247
}
```

---

#### 4. Get Analysis Statistics
**GET** `/api/v1/council/analyses/stats`

Get aggregated statistics from stored analyses.

**Response:**
```json
{
  "success": true,
  "stats": {
    "total_analyses": 1247,
    "verdicts": {
      "malicious": 342,
      "benign": 856,
      "uncertain": 49
    },
    "average_risk_score": 34.5,
    "average_confidence": 88.3,
    "threat_levels": {
      "critical": 89,
      "high": 253,
      "medium": 421,
      "low": 484
    },
    "debates_conducted": 127,
    "human_reviews_required": 34
  }
}
```

---

#### 5. Get Specific Analysis
**GET** `/api/v1/council/analyses/decision/{decision_id}`

Retrieve a specific analysis by decision ID.

**Response:**
```json
{
  "success": true,
  "analysis": {
    "decision_id": "decision_abc123",
    "package_name": "suspicious-crypto-lib",
    "package_version": "1.0.0",
    "verdict": "malicious",
    "final_risk_score": 96.0,
    "final_confidence": 92.0,
    "threat_level": "critical",
    "consensus_result": {...},
    "agent_responses": [...],
    "overseer_validation": {...},
    "created_at": "2026-02-01T20:30:00Z"
  }
}
```

---

## Project Structure

```
llm-council/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                    # FastAPI application
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py                # Configuration management
â”‚   â””â”€â”€ prompts/                   # Agent system prompts
â”‚       â”œâ”€â”€ code_intelligence.txt
â”‚       â”œâ”€â”€ threat_intelligence.txt
â”‚       â”œâ”€â”€ behavioral_intelligence.txt
â”‚       â””â”€â”€ overseer.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents.py                  # Agent implementations
â”‚   â”œâ”€â”€ consensus.py               # Consensus & debate logic
â”‚   â”œâ”€â”€ models.py                  # Pydantic data models
â”‚   â”œâ”€â”€ orchestrator.py            # Main orchestration
â”‚   â”œâ”€â”€ llm_clients.py             # LLM provider clients
â”‚   â”œâ”€â”€ overseer.py                # Overseer validation logic
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”œâ”€â”€ mongo_crud/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ database/              # MongoDB operations
â”‚       â”‚   â””â”€â”€ mongodb.py
â”‚       â”œâ”€â”€ models/                # Database models
â”‚       â”œâ”€â”€ schemas/               # API schemas
â”‚       â””â”€â”€ routers/               # API endpoints
â”‚           â””â”€â”€ council.py
â”œâ”€â”€ cerberus-threat-analysis/      # Frontend React application
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py                  # Test files
â”œâ”€â”€ test_benign_package.json       # Test data (benign)
â”œâ”€â”€ test_malicious_package.json    # Test data (malicious)
â”œâ”€â”€ .env                           # Environment variables
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ Dockerfile                     # Docker configuration
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

---

## Testing

### Using Test JSON Files

The repository includes two test files:

**1. Benign Package** (`test_benign_package.json`)
- Clean lodash package with no threats
- Expected verdict: BENIGN
- Low risk score

**2. Malicious Package** (`test_malicious_package.json`)
- Contains multiple threat indicators
- Expected verdict: MALICIOUS
- High risk score

### Run Test Analysis

```bash
# Test with malicious package
curl -X POST http://localhost:8080/analyze \
  -H "Content-Type: application/json" \
  -d @test_malicious_package.json

# Test with benign package
curl -X POST http://localhost:8080/analyze \
  -H "Content-Type: application/json" \
  -d @test_benign_package.json
```

### Query Results

```bash
# Get all analyses
curl http://localhost:8080/api/v1/council/analyses

# Get statistics
curl http://localhost:8080/api/v1/council/analyses/stats

# Get specific analysis
curl http://localhost:8080/api/v1/council/analyses/decision/{decision_id}
```

### Using the Web Interface

Access the frontend at the deployed URL to:
1. Paste JSON test data (JSON tab is default)
2. Submit for analysis
3. View detailed results with agent breakdowns
4. Browse analysis history in dashboard
5. View statistics and trends

---

## Deployment

### Docker Deployment

```bash
# Build Docker image
docker build -t llm-council:latest .

# Run locally
docker run -p 8080:8080 --env-file .env llm-council:latest

# Push to Google Container Registry
docker tag llm-council:latest gcr.io/PROJECT_ID/llm-council:latest
docker push gcr.io/PROJECT_ID/llm-council:latest
```

### Google Cloud Run

1. Push Docker image to GCR
2. Deploy from GCP Console â†’ Cloud Run
3. Set environment variables (API keys, MongoDB URI)
4. Configure:
   - Port: 8080
   - Memory: 2 GiB
   - CPU: 2
   - Request timeout: 300 seconds

---

## Future Enhancements

### Immediate Roadmap
- **Fine-tuned LLMs**: Deploy custom models trained on security datasets (CVEs, malicious packages, attack signatures)
- **Enhanced Overseer**: Machine learning model for better hallucination detection and quality scoring
- **Real-time Scanning**: Integration with npm/PyPI registries for automated package monitoring

### Long-term Vision
- **Advanced Threat Intelligence**: Connect to CVE databases, MITRE ATT&CK, and threat feeds
- **Human-in-the-Loop**: Web interface for security analysts to review flagged packages
- **Automated Response**: API webhooks for immediate registry notifications and takedown requests
- **Continuous Learning**: Feedback loop for improving agent accuracy based on analyst reviews
- **Multi-Registry Support**: Extend beyond npm to PyPI, RubyGems, Maven, NuGet
- **Behavioral Sandboxing**: Integrate dynamic analysis sandbox for runtime behavior capture

---

## Response Structure Details

Each analysis response includes:

1. **Agent Responses**: Individual assessments from all three specialized agents
2. **Overseer Validation**: Quality checks, hallucination detection, and consistency verification
3. **Consensus Result**: Weighted final decision with confidence scores and variance analysis
4. **Debate Transcript**: Full record if debate was conducted, with round-by-round analysis
5. **Metadata**: Tokens used, estimated cost, analysis duration, timestamps

---
